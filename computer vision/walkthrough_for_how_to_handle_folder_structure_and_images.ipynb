{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "WCxSmokWEKUJ"
   },
   "source": [
    "# Project: Plant Seedlings Classicication.\n",
    "\n",
    "### Data Description:\n",
    "\n",
    "- You are provided with a training set and a test set of images of plant seedlings at various stages of grown. \n",
    "- Each image has a filename that is its unique id. \n",
    "- The dataset comprises 12 plant species.\n",
    "- The goal of the competition is to create a classifier capable of determining a plant's species from a photo.\n",
    "\n",
    "### Dataset:\n",
    "- The project is from a dataset from Kaggle.\n",
    "- Link to the Kaggle project site:https://www.kaggle.com/c/plant-seedlings-classification/data\n",
    "- The dataset has to be downloaded from the above Kagglewebsite.\n",
    "\n",
    "### Context:\n",
    "\n",
    "- Can you differentiate a weed from a crop seedling?\n",
    "- The ability to do so effectively can mean better crop yields and better stewardship of the environment.\n",
    "- The Aarhus University Signal Processing group, in collaboration with University of Southern Denmark, has recently released a dataset containing images of unique plants belonging to 12 species at several growth stages.\n",
    "\n",
    "### Objective:\n",
    "- To implement the techniques learnt as a part of the course.\n",
    "\n",
    "### Learning Outcomes:\n",
    "- Pre-processing of image data.\n",
    "- Visualization of images.\n",
    "- Building CNN.\n",
    "- Evaluate the Model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "lw8IuZwV-PAL",
    "outputId": "0366a02f-8d72-4497-8184-188dd83d83ff"
   },
   "outputs": [],
   "source": [
    "# Import necessary libraries.\n",
    "import cv2\n",
    "import math\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from glob import glob\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPool2D, GlobalMaxPooling2D\n",
    "from tensorflow.keras.layers import BatchNormalization\n",
    "from tensorflow.keras.optimizers import RMSprop, Adam\n",
    "from keras.utils.np_utils import to_categorical # convert to one-hot-encoding\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "G4U1Z7p__vOd"
   },
   "outputs": [],
   "source": [
    "# Set the path to the dataset folder. (The dataset contains image folder: \"train\")\n",
    "#train_path = \"train.zip\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "K_sXNBZHA-FY"
   },
   "outputs": [],
   "source": [
    "# Make different folders for train and test data in the current directory of Google Colab notebook. (using mkdir)\n",
    "#!mkdir temp_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "C6770cFdHDc9"
   },
   "source": [
    "# Unziping train file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "L2IHlupb_s8Q"
   },
   "outputs": [
    {
     "ename": "IndentationError",
     "evalue": "unexpected indent (<ipython-input-5-2de5aba03e73>, line 4)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-5-2de5aba03e73>\"\u001b[1;36m, line \u001b[1;32m4\u001b[0m\n\u001b[1;33m    zip.extractall('./temp_train')\u001b[0m\n\u001b[1;37m    ^\u001b[0m\n\u001b[1;31mIndentationError\u001b[0m\u001b[1;31m:\u001b[0m unexpected indent\n"
     ]
    }
   ],
   "source": [
    "# Extract the files from dataset to temp_train and temp_test folders (as the dataset is a zip file.)\n",
    "#from zipfile import ZipFile\n",
    "#with ZipFile(train_path, 'r') as zip:\n",
    "#  zip.extractall('./temp_train')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 17
    },
    "colab_type": "code",
    "id": "AuVK04TO--Jr",
    "outputId": "b97ae868-398a-47ff-b1ec-93e021cc07d7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./train\\Black-grass\\0050f38b3.png\n",
      "['./train', 'Black-grass', '0050f38b3.png']\n",
      "./train\\Black-grass\\0183fdf68.png\n",
      "['./train', 'Black-grass', '0183fdf68.png']\n",
      "./train\\Black-grass\\0260cffa8.png\n",
      "['./train', 'Black-grass', '0260cffa8.png']\n",
      "./train\\Black-grass\\05eedce4d.png\n",
      "['./train', 'Black-grass', '05eedce4d.png']\n",
      "./train\\Black-grass\\075d004bc.png\n",
      "['./train', 'Black-grass', '075d004bc.png']\n",
      "./train\\Black-grass\\078eae073.png\n",
      "['./train', 'Black-grass', '078eae073.png']\n",
      "./train\\Black-grass\\082314602.png\n",
      "['./train', 'Black-grass', '082314602.png']\n",
      "./train\\Black-grass\\0ace21089.png\n",
      "['./train', 'Black-grass', '0ace21089.png']\n",
      "./train\\Black-grass\\0b228a6b8.png\n",
      "['./train', 'Black-grass', '0b228a6b8.png']\n",
      "./train\\Black-grass\\0b3e7a7a9.png\n",
      "['./train', 'Black-grass', '0b3e7a7a9.png']\n",
      "./train\\Black-grass\\0bb75ded8.png\n",
      "['./train', 'Black-grass', '0bb75ded8.png']\n",
      "./train\\Black-grass\\0be707615.png\n",
      "['./train', 'Black-grass', '0be707615.png']\n",
      "./train\\Black-grass\\0c67c3fc3.png\n",
      "['./train', 'Black-grass', '0c67c3fc3.png']\n",
      "./train\\Black-grass\\0d1a9985f.png\n",
      "['./train', 'Black-grass', '0d1a9985f.png']\n",
      "./train\\Black-grass\\0d28c429b.png\n",
      "['./train', 'Black-grass', '0d28c429b.png']\n"
     ]
    }
   ],
   "source": [
    "path = \"./train/*/*.png\"                              # The path to all images in training set. (* means include all folders and files.)\n",
    "files = glob(path)\n",
    "\n",
    "trainImg = []                                              # Initialize empty list to store the image data as numbers.\n",
    "trainLabel = []                                            # Initialize empty list to store the labels of images\n",
    "j = 1\n",
    "num = len(files)\n",
    "\n",
    "# Obtain images and resizing, obtain labels\n",
    "for img in files[0:15]:\n",
    "    '''\n",
    "    Append the image data to trainImg list.\n",
    "    Append the labels to trainLabel list.\n",
    "    '''\n",
    "    print(str(j) + \"/\" + str(num), end=\"\\r\")\n",
    "    print(img)\n",
    "    print(img.split(sep = '\\\\', maxsplit = 4))\n",
    "    trainImg.append(cv2.resize(cv2.imread(img), (128, 128)))  # Get image (with resizing to 128x128)\n",
    "    trainLabel.append(img.split('\\\\',maxsplit = 4)[-2])  # Get image label (folder name contains the class to which the image belong)\n",
    "    j += 1\n",
    "\n",
    "trainImg = np.asarray(trainImg)  # Train images set\n",
    "trainLabel = pd.DataFrame(trainLabel)  # Train labels set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "2X1I66hDfg9j",
    "outputId": "9aaab9ce-f957-41ca-9270-ca48910a4baa"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(15, 128, 128, 3)\n",
      "(15, 1)\n"
     ]
    }
   ],
   "source": [
    "print(trainImg.shape)\n",
    "print(trainLabel.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Wl9GYjQJrdTm"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              0\n",
      "0   Black-grass\n",
      "1   Black-grass\n",
      "2   Black-grass\n",
      "3   Black-grass\n",
      "4   Black-grass\n",
      "5   Black-grass\n",
      "6   Black-grass\n",
      "7   Black-grass\n",
      "8   Black-grass\n",
      "9   Black-grass\n",
      "10  Black-grass\n",
      "11  Black-grass\n",
      "12  Black-grass\n",
      "13  Black-grass\n",
      "14  Black-grass\n"
     ]
    }
   ],
   "source": [
    "print(trainLabel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "walkthrough_for_how_to_handle_folder_structure_and_images.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
