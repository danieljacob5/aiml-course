{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project Description: Twitter US Airline Sentiment, Natural Language Processing\n",
    "\n",
    "\n",
    "\n",
    "<b>Data Description:</b> \n",
    "\n",
    "A sentiment analysis job about the problems of each major U.S. airline. Twitter data was scraped from February of 2015 and contributors were asked to first classify positive, negative, and neutral tweets, followed by categorizing negative reasons (such as \"late flight\" or \"rude service\").\n",
    "\n",
    "\n",
    "<b>Dataset:</b> \n",
    "\n",
    "The project is from a dataset from Kaggle. Link to the Kaggle project site:https://www.kaggle.com/crowdflower/twitter-airline-sentiment The dataset has to be downloaded from the above Kaggle website.\n",
    "\n",
    "The dataset has the following columns:\n",
    "- tweet_id \n",
    "- airline_sentiment \n",
    "- airline_sentiment_confidence \n",
    "- negative reason\n",
    "- negativereason_confidence \n",
    "- airline  \n",
    "- airline_sentiment_gold  \n",
    "- name \n",
    "- negativereason_gold \n",
    "- retweet_count  \n",
    "- text  \n",
    "- tweet_coord  \n",
    "- tweet_created  \n",
    "- tweet_location \n",
    "- user_timezone\n",
    "\n",
    "\n",
    "<b>Objective:</b> \n",
    "\n",
    "To implement the techniques learnt as a part of the course.\n",
    "\n",
    "\n",
    "<b>Learning Outcomes:</b>\n",
    "- Basic understanding of text pre-processing.\n",
    "- What to do after text pre-processing: \n",
    "- Bag of wordsoTf-idf\n",
    "- Build the classification model.\n",
    "- Evaluate the Model.Steps and tasks:\n",
    "\n",
    "<b>Tasks:</b>\n",
    "\n",
    "1. Import the libraries, load dataset, print shape of data, data description (5 Marks)\n",
    "2. Understand of data-columns (5 Marks)<br>     \n",
    "        a. Drop all other columns except ‚Äútext‚Äùand ‚Äúairline_sentiment‚Äù.     \n",
    "        b. Check the shape of data.     \n",
    "        c. Print first 5 rows of data.\n",
    "3. Text pre-processing: Data preparation (20 Marks)\n",
    "    \n",
    "        a. Html tag removal.    \n",
    "        b. Tokenization.     \n",
    "        c. Remove the numbers.     \n",
    "        d. Removal of Special Characters and Punctuations.     \n",
    "        e. Conversion to lowercase.     \n",
    "        f. Lemmatize or stemming.    \n",
    "        g. Join the words in the list to convert back to text string in the dataframe. (So that each row contains the data in text format.)     \n",
    "        h. Print first 5 rows of data after pre-processing. \n",
    "4. Vectorization (10 Marks)<br>\n",
    "        a. Use CountVectorizer.<br>     \n",
    "        b. Use TfidfVectorizer.<br> \n",
    "5. Fit and evaluate model using both type of vectorization (6+6 Marks)\n",
    "6. Summarize your understanding of the application of Various Pre-processing and Vectorization and performance of your modelon this dataset (8 Marks)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import the libraries, load dataset, print shape of data, data description "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re, string, unicodedata\n",
    "import nltk\n",
    "import textsearch\n",
    "import contractions\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>airline_sentiment</th>\n",
       "      <th>airline_sentiment_confidence</th>\n",
       "      <th>negativereason</th>\n",
       "      <th>negativereason_confidence</th>\n",
       "      <th>airline</th>\n",
       "      <th>airline_sentiment_gold</th>\n",
       "      <th>name</th>\n",
       "      <th>negativereason_gold</th>\n",
       "      <th>retweet_count</th>\n",
       "      <th>text</th>\n",
       "      <th>tweet_coord</th>\n",
       "      <th>tweet_created</th>\n",
       "      <th>tweet_location</th>\n",
       "      <th>user_timezone</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>570306133677760513</td>\n",
       "      <td>neutral</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Virgin America</td>\n",
       "      <td>NaN</td>\n",
       "      <td>cairdin</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>@VirginAmerica What @dhepburn said.</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2015-02-24 11:35:52 -0800</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Eastern Time (US &amp; Canada)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>570301130888122368</td>\n",
       "      <td>positive</td>\n",
       "      <td>0.3486</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>Virgin America</td>\n",
       "      <td>NaN</td>\n",
       "      <td>jnardino</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>@VirginAmerica plus you've added commercials t...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2015-02-24 11:15:59 -0800</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Pacific Time (US &amp; Canada)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>570301083672813571</td>\n",
       "      <td>neutral</td>\n",
       "      <td>0.6837</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Virgin America</td>\n",
       "      <td>NaN</td>\n",
       "      <td>yvonnalynn</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>@VirginAmerica I didn't today... Must mean I n...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2015-02-24 11:15:48 -0800</td>\n",
       "      <td>Lets Play</td>\n",
       "      <td>Central Time (US &amp; Canada)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>570301031407624196</td>\n",
       "      <td>negative</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>Bad Flight</td>\n",
       "      <td>0.7033</td>\n",
       "      <td>Virgin America</td>\n",
       "      <td>NaN</td>\n",
       "      <td>jnardino</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>@VirginAmerica it's really aggressive to blast...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2015-02-24 11:15:36 -0800</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Pacific Time (US &amp; Canada)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>570300817074462722</td>\n",
       "      <td>negative</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>Can't Tell</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>Virgin America</td>\n",
       "      <td>NaN</td>\n",
       "      <td>jnardino</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>@VirginAmerica and it's a really big bad thing...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2015-02-24 11:14:45 -0800</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Pacific Time (US &amp; Canada)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             tweet_id airline_sentiment  airline_sentiment_confidence  \\\n",
       "0  570306133677760513           neutral                        1.0000   \n",
       "1  570301130888122368          positive                        0.3486   \n",
       "2  570301083672813571           neutral                        0.6837   \n",
       "3  570301031407624196          negative                        1.0000   \n",
       "4  570300817074462722          negative                        1.0000   \n",
       "\n",
       "  negativereason  negativereason_confidence         airline  \\\n",
       "0            NaN                        NaN  Virgin America   \n",
       "1            NaN                     0.0000  Virgin America   \n",
       "2            NaN                        NaN  Virgin America   \n",
       "3     Bad Flight                     0.7033  Virgin America   \n",
       "4     Can't Tell                     1.0000  Virgin America   \n",
       "\n",
       "  airline_sentiment_gold        name negativereason_gold  retweet_count  \\\n",
       "0                    NaN     cairdin                 NaN              0   \n",
       "1                    NaN    jnardino                 NaN              0   \n",
       "2                    NaN  yvonnalynn                 NaN              0   \n",
       "3                    NaN    jnardino                 NaN              0   \n",
       "4                    NaN    jnardino                 NaN              0   \n",
       "\n",
       "                                                text tweet_coord  \\\n",
       "0                @VirginAmerica What @dhepburn said.         NaN   \n",
       "1  @VirginAmerica plus you've added commercials t...         NaN   \n",
       "2  @VirginAmerica I didn't today... Must mean I n...         NaN   \n",
       "3  @VirginAmerica it's really aggressive to blast...         NaN   \n",
       "4  @VirginAmerica and it's a really big bad thing...         NaN   \n",
       "\n",
       "               tweet_created tweet_location               user_timezone  \n",
       "0  2015-02-24 11:35:52 -0800            NaN  Eastern Time (US & Canada)  \n",
       "1  2015-02-24 11:15:59 -0800            NaN  Pacific Time (US & Canada)  \n",
       "2  2015-02-24 11:15:48 -0800      Lets Play  Central Time (US & Canada)  \n",
       "3  2015-02-24 11:15:36 -0800            NaN  Pacific Time (US & Canada)  \n",
       "4  2015-02-24 11:14:45 -0800            NaN  Pacific Time (US & Canada)  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#import data and display first 5 rows\n",
    "data = pd.read_csv('Tweets.csv')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The shape of the data is (14640, 15)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>airline_sentiment_confidence</th>\n",
       "      <th>negativereason_confidence</th>\n",
       "      <th>retweet_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1.464000e+04</td>\n",
       "      <td>14640.000000</td>\n",
       "      <td>10522.000000</td>\n",
       "      <td>14640.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>5.692184e+17</td>\n",
       "      <td>0.900169</td>\n",
       "      <td>0.638298</td>\n",
       "      <td>0.082650</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>7.791112e+14</td>\n",
       "      <td>0.162830</td>\n",
       "      <td>0.330440</td>\n",
       "      <td>0.745778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>5.675883e+17</td>\n",
       "      <td>0.335000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>5.685592e+17</td>\n",
       "      <td>0.692300</td>\n",
       "      <td>0.360600</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>5.694779e+17</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.670600</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>5.698905e+17</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>5.703106e+17</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>44.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           tweet_id  airline_sentiment_confidence  negativereason_confidence  \\\n",
       "count  1.464000e+04                  14640.000000               10522.000000   \n",
       "mean   5.692184e+17                      0.900169                   0.638298   \n",
       "std    7.791112e+14                      0.162830                   0.330440   \n",
       "min    5.675883e+17                      0.335000                   0.000000   \n",
       "25%    5.685592e+17                      0.692300                   0.360600   \n",
       "50%    5.694779e+17                      1.000000                   0.670600   \n",
       "75%    5.698905e+17                      1.000000                   1.000000   \n",
       "max    5.703106e+17                      1.000000                   1.000000   \n",
       "\n",
       "       retweet_count  \n",
       "count   14640.000000  \n",
       "mean        0.082650  \n",
       "std         0.745778  \n",
       "min         0.000000  \n",
       "25%         0.000000  \n",
       "50%         0.000000  \n",
       "75%         0.000000  \n",
       "max        44.000000  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 14640 entries, 0 to 14639\n",
      "Data columns (total 15 columns):\n",
      "tweet_id                        14640 non-null int64\n",
      "airline_sentiment               14640 non-null object\n",
      "airline_sentiment_confidence    14640 non-null float64\n",
      "negativereason                  9178 non-null object\n",
      "negativereason_confidence       10522 non-null float64\n",
      "airline                         14640 non-null object\n",
      "airline_sentiment_gold          40 non-null object\n",
      "name                            14640 non-null object\n",
      "negativereason_gold             32 non-null object\n",
      "retweet_count                   14640 non-null int64\n",
      "text                            14640 non-null object\n",
      "tweet_coord                     1019 non-null object\n",
      "tweet_created                   14640 non-null object\n",
      "tweet_location                  9907 non-null object\n",
      "user_timezone                   9820 non-null object\n",
      "dtypes: float64(2), int64(2), object(11)\n",
      "memory usage: 1.7+ MB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "#display shape of data and description\n",
    "print('The shape of the data is', data.shape)\n",
    "display(data.describe())\n",
    "print(data.info())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Understand of data-columns (5 Marks)\n",
    " a. Drop all other columns except ‚Äútext‚Äùand ‚Äúairline_sentiment‚Äù.     \n",
    " b. Check the shape of data.     \n",
    " c. Print first 5 rows of data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The shape is (14640, 2)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>airline_sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>@VirginAmerica What @dhepburn said.</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>@VirginAmerica plus you've added commercials t...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>@VirginAmerica I didn't today... Must mean I n...</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>@VirginAmerica it's really aggressive to blast...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>@VirginAmerica and it's a really big bad thing...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text airline_sentiment\n",
       "0                @VirginAmerica What @dhepburn said.           neutral\n",
       "1  @VirginAmerica plus you've added commercials t...          positive\n",
       "2  @VirginAmerica I didn't today... Must mean I n...           neutral\n",
       "3  @VirginAmerica it's really aggressive to blast...          negative\n",
       "4  @VirginAmerica and it's a really big bad thing...          negative"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#create new dataframe with only text and airline sentiment columns\n",
    "sentiment = data[['text','airline_sentiment']]\n",
    "print('The shape is', sentiment.shape)\n",
    "display(sentiment.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Text pre-processing: Data preparation (20 Marks)\n",
    "\n",
    " a. Html tag removal.    \n",
    " b. Tokenization.     \n",
    " c. Remove the numbers.     \n",
    " d. Removal of Special Characters and Punctuations.     \n",
    " e. Conversion to lowercase.     \n",
    " f. Lemmatize or stemming.    \n",
    " g. Join the words in the list to convert back to text string in the dataframe. (So that each row contains the data in text format.)     \n",
    " h. Print first 5 rows of data after pre-processing. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The next several steps will individually build a function, test on the dataframe to ensure it's working properly and without error\n",
    "# then combine the functions at the end and save as a new dataframe that's ready for preprocessing\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#remove html tags\n",
    "def strip_html(text):\n",
    "    soup = BeautifulSoup(text, \"html.parser\")\n",
    "    return soup.get_text()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                      @VirginAmerica What @dhepburn said.\n",
       "1        @VirginAmerica plus you've added commercials t...\n",
       "2        @VirginAmerica I didn't today... Must mean I n...\n",
       "3        @VirginAmerica it's really aggressive to blast...\n",
       "4        @VirginAmerica and it's a really big bad thing...\n",
       "5        @VirginAmerica seriously would pay $30 a fligh...\n",
       "6        @VirginAmerica yes, nearly every time I fly VX...\n",
       "7        @VirginAmerica Really missed a prime opportuni...\n",
       "8          @virginamerica Well, I didn't‚Ä¶but NOW I DO! :-D\n",
       "9        @VirginAmerica it was amazing, and arrived an ...\n",
       "10       @VirginAmerica did you know that suicide is th...\n",
       "11       @VirginAmerica I <3 pretty graphics. so much b...\n",
       "12       @VirginAmerica This is such a great deal! Alre...\n",
       "13       @VirginAmerica @virginmedia I'm flying your #f...\n",
       "14                                  @VirginAmerica Thanks!\n",
       "15           @VirginAmerica SFO-PDX schedule is still MIA.\n",
       "16       @VirginAmerica So excited for my first cross c...\n",
       "17       @VirginAmerica  I flew from NYC to SFO last we...\n",
       "18                         I ‚ù§Ô∏è flying @VirginAmerica. ‚ò∫Ô∏èüëç\n",
       "19       @VirginAmerica you know what would be amazingl...\n",
       "20       @VirginAmerica why are your first fares in May...\n",
       "21       @VirginAmerica I love this graphic. http://t.c...\n",
       "22       @VirginAmerica I love the hipster innovation. ...\n",
       "23       @VirginAmerica will you be making BOS>LAS non ...\n",
       "24       @VirginAmerica you guys messed up my seating.....\n",
       "25       @VirginAmerica status match program.  I applie...\n",
       "26       @VirginAmerica What happened 2 ur vegan food o...\n",
       "27       @VirginAmerica do you miss me? Don't worry we'...\n",
       "28       @VirginAmerica amazing to me that we can't get...\n",
       "29       @VirginAmerica LAX to EWR - Middle seat on a r...\n",
       "                               ...                        \n",
       "14610    @AmericanAir I understand the weather issue bu...\n",
       "14611    @AmericanAir guarantee no retribution? If so, ...\n",
       "14612    @AmericanAir a friend is having flight Cancell...\n",
       "14613    @AmericanAir I used the \"call back\" feature wi...\n",
       "14614    @AmericanAir I need to be at work tomorrow at ...\n",
       "14615    @AmericanAir  ugh Dump us in dfw w/no luggage ...\n",
       "14616    @AmericanAir Cancelled Flights my flight, does...\n",
       "14617              @AmericanAir DMing you now! Big thanks.\n",
       "14618    @AmericanAir 3078 is overweight so you pull 2 ...\n",
       "14619    @AmericanAir I love your company and your staf...\n",
       "14620    @AmericanAir I wait 2+ hrs for CS to call me b...\n",
       "14621    @AmericanAir I've been on hold for 55 mins abo...\n",
       "14622    I just need a place to sleep when I land witho...\n",
       "14623    @AmericanAir Love the new planes for the JFK-L...\n",
       "14624    @AmericanAir Call me Chairman, or call me Emer...\n",
       "14625    @AmericanAir Flight 236 was great. Fantastic c...\n",
       "14626    @AmericanAir Flight 953 NYC-Buenos Aires has b...\n",
       "14627    @AmericanAir Flight Cancelled Flightled, can't...\n",
       "14628    Thank you. ‚Äú@AmericanAir: @jlhalldc Customer R...\n",
       "14629    @AmericanAir How do I change my flight if the ...\n",
       "14630                          @AmericanAir Thanks! He is.\n",
       "14631    @AmericanAir thx for nothing on getting us out...\n",
       "14632    ‚Äú@AmericanAir: @TilleyMonsta George, that does...\n",
       "14633    @AmericanAir my flight was Cancelled Flightled...\n",
       "14634           @AmericanAir right on cue with the delaysüëå\n",
       "14635    @AmericanAir thank you we got on a different f...\n",
       "14636    @AmericanAir leaving over 20 minutes Late Flig...\n",
       "14637    @AmericanAir Please bring American Airlines to...\n",
       "14638    @AmericanAir you have my money, you change my ...\n",
       "14639    @AmericanAir we have 8 ppl so we need 2 know h...\n",
       "Name: text, Length: 14640, dtype: object"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#check to make sure function runs on dataframe\n",
    "sentiment['text'].apply(strip_html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#define function for replacing contractions using the contractions library\n",
    "def replace_contractions(text):\n",
    "    return contractions.fix(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                      @VirginAmerica What @dhepburn said.\n",
       "1        @VirginAmerica plus you have added commercials...\n",
       "2        @VirginAmerica I did not today... Must mean I ...\n",
       "3        @VirginAmerica it is really aggressive to blas...\n",
       "4        @VirginAmerica and it is a really big bad thin...\n",
       "5        @VirginAmerica seriously would pay $30 a fligh...\n",
       "6        @VirginAmerica yes, nearly every time I fly VX...\n",
       "7        @VirginAmerica Really missed a prime opportuni...\n",
       "8         @virginamerica Well, I did not‚Ä¶but NOW I DO! :-D\n",
       "9        @VirginAmerica it was amazing, and arrived an ...\n",
       "10       @VirginAmerica did you know that suicide is th...\n",
       "11       @VirginAmerica I &lt;3 pretty graphics. so muc...\n",
       "12       @VirginAmerica This is such a great deal! Alre...\n",
       "13       @VirginAmerica @virginmedia I am flying your #...\n",
       "14                                  @VirginAmerica Thanks!\n",
       "15           @VirginAmerica SFO-PDX schedule is still MIA.\n",
       "16       @VirginAmerica So excited for my first cross c...\n",
       "17       @VirginAmerica  I flew from NYC to SFO last we...\n",
       "18                         I ‚ù§Ô∏è flying @VirginAmerica. ‚ò∫Ô∏èüëç\n",
       "19       @VirginAmerica you know what would be amazingl...\n",
       "20       @VirginAmerica why are your first fares in May...\n",
       "21       @VirginAmerica I love this graphic. http://t.c...\n",
       "22       @VirginAmerica I love the hipster innovation. ...\n",
       "23       @VirginAmerica will you be making BOS&gt;LAS n...\n",
       "24       @VirginAmerica you guys messed up my seating.....\n",
       "25       @VirginAmerica status match program.  I applie...\n",
       "26       @VirginAmerica What happened 2 ur vegan food o...\n",
       "27       @VirginAmerica do you miss me? do not worry we...\n",
       "28       @VirginAmerica amazing to me that we can not g...\n",
       "29       @VirginAmerica LAX to EWR - Middle seat on a r...\n",
       "                               ...                        \n",
       "14610    @AmericanAir I understand the weather issue bu...\n",
       "14611    @AmericanAir guarantee no retribution? If so, ...\n",
       "14612    @AmericanAir a friend is having flight Cancell...\n",
       "14613    @AmericanAir I used the \"call back\" feature wi...\n",
       "14614    @AmericanAir I need to be at work tomorrow at ...\n",
       "14615    @AmericanAir  ugh Dump us in dfw w/no luggage ...\n",
       "14616    @AmericanAir Cancelled Flights my flight, does...\n",
       "14617              @AmericanAir DMing you now! Big thanks.\n",
       "14618    @AmericanAir 3078 is overweight so you pull 2 ...\n",
       "14619    @AmericanAir I love your company and your staf...\n",
       "14620    @AmericanAir I wait 2+ hrs for CS to call me b...\n",
       "14621    @AmericanAir I have been on hold for 55 mins a...\n",
       "14622    I just need a place to sleep when I land witho...\n",
       "14623    @AmericanAir Love the new planes for the JFK-L...\n",
       "14624    @AmericanAir Call me Chairman, or call me Emer...\n",
       "14625    @AmericanAir Flight 236 was great. Fantastic c...\n",
       "14626    @AmericanAir Flight 953 NYC-Buenos Aires has b...\n",
       "14627    @AmericanAir Flight Cancelled Flightled, can n...\n",
       "14628    Thank you. ‚Äú@AmericanAir: @jlhalldc Customer R...\n",
       "14629    @AmericanAir How do I change my flight if the ...\n",
       "14630                          @AmericanAir Thanks! He is.\n",
       "14631    @AmericanAir thx for nothing on getting us out...\n",
       "14632    ‚Äú@AmericanAir: @TilleyMonsta George, that does...\n",
       "14633    @AmericanAir my flight was Cancelled Flightled...\n",
       "14634           @AmericanAir right on cue with the delaysüëå\n",
       "14635    @AmericanAir thank you we got on a different f...\n",
       "14636    @AmericanAir leaving over 20 minutes Late Flig...\n",
       "14637    @AmericanAir Please bring American Airlines to...\n",
       "14638    @AmericanAir you have my money, you change my ...\n",
       "14639    @AmericanAir we have 8 ppl so we need 2 know h...\n",
       "Name: text, Length: 14640, dtype: object"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#check to make sure function runs on dataframe\n",
    "sentiment['text'].apply(replace_contractions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\jharnack\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "import nltk\n",
    "nltk.download('punkt')\n",
    "\n",
    "#tokenize\n",
    "def tokenizer(text):\n",
    "    tkn = word_tokenize(text)\n",
    "    return tkn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0           [@, VirginAmerica, What, @, dhepburn, said, .]\n",
       "1        [@, VirginAmerica, plus, you, 've, added, comm...\n",
       "2        [@, VirginAmerica, I, did, n't, today, ..., Mu...\n",
       "3        [@, VirginAmerica, it, 's, really, aggressive,...\n",
       "4        [@, VirginAmerica, and, it, 's, a, really, big...\n",
       "5        [@, VirginAmerica, seriously, would, pay, $, 3...\n",
       "6        [@, VirginAmerica, yes, ,, nearly, every, time...\n",
       "7        [@, VirginAmerica, Really, missed, a, prime, o...\n",
       "8        [@, virginamerica, Well, ,, I, didn't‚Ä¶but, NOW...\n",
       "9        [@, VirginAmerica, it, was, amazing, ,, and, a...\n",
       "10       [@, VirginAmerica, did, you, know, that, suici...\n",
       "11       [@, VirginAmerica, I, &, lt, ;, 3, pretty, gra...\n",
       "12       [@, VirginAmerica, This, is, such, a, great, d...\n",
       "13       [@, VirginAmerica, @, virginmedia, I, 'm, flyi...\n",
       "14                           [@, VirginAmerica, Thanks, !]\n",
       "15       [@, VirginAmerica, SFO-PDX, schedule, is, stil...\n",
       "16       [@, VirginAmerica, So, excited, for, my, first...\n",
       "17       [@, VirginAmerica, I, flew, from, NYC, to, SFO...\n",
       "18               [I, ‚ù§Ô∏è, flying, @, VirginAmerica, ., ‚ò∫Ô∏èüëç]\n",
       "19       [@, VirginAmerica, you, know, what, would, be,...\n",
       "20       [@, VirginAmerica, why, are, your, first, fare...\n",
       "21       [@, VirginAmerica, I, love, this, graphic, ., ...\n",
       "22       [@, VirginAmerica, I, love, the, hipster, inno...\n",
       "23       [@, VirginAmerica, will, you, be, making, BOS,...\n",
       "24       [@, VirginAmerica, you, guys, messed, up, my, ...\n",
       "25       [@, VirginAmerica, status, match, program, ., ...\n",
       "26       [@, VirginAmerica, What, happened, 2, ur, vega...\n",
       "27       [@, VirginAmerica, do, you, miss, me, ?, Do, n...\n",
       "28       [@, VirginAmerica, amazing, to, me, that, we, ...\n",
       "29       [@, VirginAmerica, LAX, to, EWR, -, Middle, se...\n",
       "                               ...                        \n",
       "14610    [@, AmericanAir, I, understand, the, weather, ...\n",
       "14611    [@, AmericanAir, guarantee, no, retribution, ?...\n",
       "14612    [@, AmericanAir, a, friend, is, having, flight...\n",
       "14613    [@, AmericanAir, I, used, the, ``, call, back,...\n",
       "14614    [@, AmericanAir, I, need, to, be, at, work, to...\n",
       "14615    [@, AmericanAir, ugh, Dump, us, in, dfw, w/no,...\n",
       "14616    [@, AmericanAir, Cancelled, Flights, my, fligh...\n",
       "14617    [@, AmericanAir, DMing, you, now, !, Big, than...\n",
       "14618    [@, AmericanAir, 3078, is, overweight, so, you...\n",
       "14619    [@, AmericanAir, I, love, your, company, and, ...\n",
       "14620    [@, AmericanAir, I, wait, 2+, hrs, for, CS, to...\n",
       "14621    [@, AmericanAir, I, 've, been, on, hold, for, ...\n",
       "14622    [I, just, need, a, place, to, sleep, when, I, ...\n",
       "14623    [@, AmericanAir, Love, the, new, planes, for, ...\n",
       "14624    [@, AmericanAir, Call, me, Chairman, ,, or, ca...\n",
       "14625    [@, AmericanAir, Flight, 236, was, great, ., F...\n",
       "14626    [@, AmericanAir, Flight, 953, NYC-Buenos, Aire...\n",
       "14627    [@, AmericanAir, Flight, Cancelled, Flightled,...\n",
       "14628    [Thank, you, ., ‚Äú, @, AmericanAir, :, @, jlhal...\n",
       "14629    [@, AmericanAir, How, do, I, change, my, fligh...\n",
       "14630               [@, AmericanAir, Thanks, !, He, is, .]\n",
       "14631    [@, AmericanAir, thx, for, nothing, on, gettin...\n",
       "14632    [‚Äú, @, AmericanAir, :, @, TilleyMonsta, George...\n",
       "14633    [@, AmericanAir, my, flight, was, Cancelled, F...\n",
       "14634    [@, AmericanAir, right, on, cue, with, the, de...\n",
       "14635    [@, AmericanAir, thank, you, we, got, on, a, d...\n",
       "14636    [@, AmericanAir, leaving, over, 20, minutes, L...\n",
       "14637    [@, AmericanAir, Please, bring, American, Airl...\n",
       "14638    [@, AmericanAir, you, have, my, money, ,, you,...\n",
       "14639    [@, AmericanAir, we, have, 8, ppl, so, we, nee...\n",
       "Name: text, Length: 14640, dtype: object"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#check to make sure function works on dataframe\n",
    "sentiment['text'].apply(tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "unexpected EOF while parsing (<ipython-input-12-e6ddfa8784e3>, line 3)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-12-e6ddfa8784e3>\"\u001b[1;36m, line \u001b[1;32m3\u001b[0m\n\u001b[1;33m    \u001b[0m\n\u001b[1;37m    ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m unexpected EOF while parsing\n"
     ]
    }
   ],
   "source": [
    "#remove numbers\n",
    "def num_remover(text):\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
